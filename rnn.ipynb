# === Step 2: Build and Use RNN Class ===
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense
from tensorflow.keras.preprocessing.text import Tokenizer

class RNN:
    def __init__(self, text, sequence_length=3, embedding_dim=10, rnn_units=8):
        self.text = text
        self.sequence_length = sequence_length
        self.embedding_dim = embedding_dim
        self.rnn_units = rnn_units
        self.tokenizer = Tokenizer()
        self.model = None
        self._prepare_data()

    def _prepare_data(self):
        # Tokenize text
        self.tokenizer.fit_on_texts([self.text])
        self.word_index = self.tokenizer.word_index
        self.vocab_size = len(self.word_index) + 1

        # Convert text to sequence of integers
        self.sequence = self.tokenizer.texts_to_sequences([self.text])[0]
        self.X = np.array([self.sequence[:self.sequence_length]])
        self.y = np.array([self.sequence[self.sequence_length]])

    def build_model(self):
        # Build RNN model
        self.model = Sequential()
        self.model.add(Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.sequence_length))
        self.model.add(SimpleRNN(units=self.rnn_units))
        self.model.add(Dense(self.vocab_size, activation='softmax'))
        self.model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    def train(self, epochs=500, verbose=0):
        self.model.fit(self.X, self.y, epochs=epochs, verbose=verbose)

    def predict_next_word(self):
        prediction = self.model.predict(self.X)
        predicted_index = np.argmax(prediction)
        return self.tokenizer.index_word.get(predicted_index, "<UNK>")

# === Step 3: Use the RNN ===
text = "Student of Delta University"
rnn = RNN(text)
rnn.build_model()
rnn.train(epochs=500)
predicted_word = rnn.predict_next_word()
print(f"\nPredicted 4th word: {predicted_word}")
